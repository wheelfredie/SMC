{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wheelfredie/SMC/blob/main/generate_hike_namecard_contact.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTG0CSPmCiJd",
        "outputId": "fd2e1410-189e-4a21-e45a-092e813bc632"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "master_path = path_to_file = '/content/drive/My Drive/SMC_scripts/smc_contact_table/'"
      ],
      "metadata": {
        "id": "92_5iyGtEasD"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reportlab\n",
        "!pip install vobject"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7txpV6SeEi34",
        "outputId": "a53df7e9-63c5-45ed-ac13-c25f24dba402"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.10/dist-packages (4.0.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab) (9.4.0)\n",
            "Requirement already satisfied: vobject in /usr/local/lib/python3.10/dist-packages (0.9.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from vobject) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4.0->vobject) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "1SdNreSgCgKX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import os\n",
        "from reportlab.lib.pagesizes import A4\n",
        "from reportlab.pdfgen import canvas\n",
        "import vobject\n",
        "\n",
        "pd.set_option('display.max_columns', 10)\n",
        "pd.set_option('display.max_rows', 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "VkTvMaD9CgKY"
      },
      "outputs": [],
      "source": [
        "from numpy.lib.twodim_base import mask_indices\n",
        "#get earliest date\n",
        "def flatten_list(list_of_lists):\n",
        "    flat_list = []\n",
        "\n",
        "    for item in list_of_lists:\n",
        "        if isinstance(item, list):\n",
        "            flat_list.extend(flatten_list(item))\n",
        "        #base case\n",
        "        else:\n",
        "            flat_list.append(item)\n",
        "    return flat_list\n",
        "\n",
        "def get_earliest_date(df):\n",
        "    return min(list(map(lambda x : pd.to_datetime(x, format='%d %b %y'),\n",
        "        set(flatten_list(list(map(lambda x: x.split(\", \"), df[\"Date of Hike\"]\n",
        "                                  .unique()))))))).strftime(\"%d %b %y\")\n",
        "\n",
        "def mmConvertpoint(mm):\n",
        "    # Convert millimeters to points\n",
        "    return mm * (72 / 25.4)\n",
        "\n",
        "def generate_name_tags(name_series, group, reserved=False):\n",
        "    if group.lower() == \"youth\":\n",
        "        group = \"Y\"\n",
        "    elif group.lower() == \"mentor\":\n",
        "        group = \"M\"\n",
        "\n",
        "    if not os.path.exists(\"name_tags_ToBePrinted\"):\n",
        "        os.makedirs(\"name_tags_ToBePrinted\")\n",
        "\n",
        "    page_width, page_height = A4  # Standard A4 size in points (72 points per inch)\n",
        "    margin_x, margin_y = 30, 30   # Margins from the edges of the paper in points\n",
        "    tag_width_mm, tag_height_mm = 85, 55  # Size of each name tag in mm\n",
        "    tag_width, tag_height = mmConvertpoint(tag_width_mm), mmConvertpoint(tag_height_mm)  # Size of each name tag in points\n",
        "\n",
        "    # Font size range for the name\n",
        "    min_name_font_size = 10\n",
        "    max_name_font_size = 30\n",
        "\n",
        "    if reserved:\n",
        "        pdf_name = master_path + f\"name_tags_ToBePrinted/Reserved_UID_{group}.pdf\"\n",
        "    else:\n",
        "        pdf_name = master_path + f\"name_tags_ToBePrinted/name_tags_{group}.pdf\"\n",
        "    c = canvas.Canvas(pdf_name, pagesize=A4)\n",
        "\n",
        "    x, y = margin_x, page_height - margin_y  # Starting position for the first name tag\n",
        "    boxes_per_page = 0  # Counter for boxes printed on each page\n",
        "    rows_per_page = 4  # Number of rows per page\n",
        "    columns_per_page = 2  # Number of columns per page\n",
        "\n",
        "    for uid, name in name_series.items():\n",
        "        # Draw guidelines all around the name tag\n",
        "        c.setStrokeColorRGB(0.7, 0.7, 0.7)  # Gray color for guidelines\n",
        "        c.setLineWidth(0.1)\n",
        "        c.line(x, y, x + tag_width, y)  # Top guideline\n",
        "        c.line(x, y - tag_height, x + tag_width, y - tag_height)  # Bottom guideline\n",
        "        c.line(x, y, x, y - tag_height)  # Left guideline\n",
        "        c.line(x + tag_width, y, x + tag_width, y - tag_height)  # Right guideline\n",
        "\n",
        "        # Find the maximum font size that fits the name in the available space\n",
        "        name_font_size = max_name_font_size\n",
        "        while c.stringWidth(name, \"Helvetica-Bold\", name_font_size) > tag_width - 10:\n",
        "            name_font_size -= 1\n",
        "            if name_font_size < min_name_font_size:\n",
        "                # If the name still doesn't fit at the smallest font size, break the loop\n",
        "                break\n",
        "\n",
        "        # Draw the name in the center both by height and width\n",
        "        c.setFont(\"Helvetica-Bold\", name_font_size)\n",
        "        text_width, text_height = c.stringWidth(name, \"Helvetica-Bold\", name_font_size), name_font_size\n",
        "        x_offset = (tag_width - text_width) / 2\n",
        "        y_offset = (tag_height - text_height) / 2  # Center by height\n",
        "        c.drawString(x + x_offset, y - y_offset, name)\n",
        "\n",
        "        # Calculate the position of the UID at the bottom right with a margin from the borders\n",
        "        uid_font_size = 10\n",
        "        uid_margin_x, uid_margin_y = 5, 5\n",
        "        uid_x = x + tag_width - uid_margin_x - c.stringWidth(\"UID: \" + group + str(uid), \"Helvetica\", uid_font_size)\n",
        "        uid_y = y - tag_height + uid_margin_y\n",
        "\n",
        "        # Draw the UID at the bottom right in a smaller font\n",
        "        c.setFont(\"Helvetica\", uid_font_size)\n",
        "        c.drawString(uid_x, uid_y, \"UID: \" + group + str(uid))\n",
        "\n",
        "        # Update x and y position for the next name tag\n",
        "        boxes_per_page += 1\n",
        "        if boxes_per_page % columns_per_page == 0:\n",
        "            # Move to the next row after completing a row\n",
        "            y -= tag_height\n",
        "            x = margin_x\n",
        "        else:\n",
        "            # Move to the next column in the same row\n",
        "            x += tag_width\n",
        "\n",
        "        # Check if the maximum number of rows per page is reached, then start a new page\n",
        "        if boxes_per_page == rows_per_page * columns_per_page:\n",
        "            c.showPage()  # Start a new page\n",
        "            x, y = margin_x, page_height - margin_y\n",
        "            boxes_per_page = 0  # Reset the boxes count for the new page\n",
        "\n",
        "    c.save()\n",
        "\n",
        "def normalize_string(s):\n",
        "    return s.lower().replace(\" \", \"\")\n",
        "\n",
        "def create_vcard(df, filename):\n",
        "    # Open file in write mode\n",
        "    with open(filename, 'w') as file:\n",
        "        for index, row in df.iterrows():\n",
        "            # Create a new vCard\n",
        "            vcard = vobject.vCard()\n",
        "\n",
        "            # Add name\n",
        "            school_company = row['School/Company']\n",
        "            smc_name = f\"SMC {row.full_name} {school_company}\"\n",
        "            vcard.add('n')\n",
        "            vcard.n.value = vobject.vcard.Name(given=smc_name)\n",
        "\n",
        "            # Add full name\n",
        "            vcard.add('fn')\n",
        "            vcard.fn.value = smc_name\n",
        "\n",
        "            # Add phone\n",
        "            tel = vcard.add('tel')\n",
        "            tel.value = str(row['Whatsapp/mobile Number'])\n",
        "            tel.type_param = 'CELL'\n",
        "\n",
        "            # Add company\n",
        "            qualification_details = row[\"Undergraduate / Postgraduate / Employed\"]\n",
        "            title = row[\"Major/Title\"]\n",
        "            company_details = f\"{current_youth_qualification[qualification_details]}, {title}\"\n",
        "            org = vcard.add('org')\n",
        "            org.value = [company_details]\n",
        "\n",
        "            # Write vCard to file\n",
        "            file.write(vcard.serialize())\n",
        "\n",
        "def process_youth():\n",
        "    current_youth_qualification = {'Undergraduate': \"UG\",\n",
        "                                   'Postgraduate' : \"PG\",\n",
        "                                   'Employed' : \"E\"}\n",
        "\n",
        "    df = pd.read_excel(master_path + \"raw_data/Members_Youth_Default View.xlsx\")\n",
        "\n",
        "    earliest_date = get_earliest_date(df)\n",
        "\n",
        "    #filter for rows with earliest date\n",
        "    df = df[df[\"Date of Hike\"].str.contains(earliest_date)]\n",
        "    df[\"full_name\"] = df[\"First_Name\"] + \" \" + df[\"Last_Name\"]\n",
        "    df[\"Date of Hike\"] = earliest_date\n",
        "    df[\"Qualification\"] = df[\"Undergraduate / Postgraduate / Employed\"]\\\n",
        "        .map(lambda x: current_youth_qualification[x])\n",
        "\n",
        "    df = df[['Date of Hike', 'full_name', 'School/Company',\n",
        "    'Major/Title', 'Qualification',\n",
        "    'Year in School or Industry', 'Email', 'Whatsapp/mobile Number']]\n",
        "\n",
        "    df.drop_duplicates(subset=[\"Email\", \"Whatsapp/mobile Number\"],\n",
        "                    keep=\"first\",\n",
        "                    inplace=True)\n",
        "    df.reset_index(drop=True,\n",
        "                inplace=True)\n",
        "\n",
        "    # df.to_csv(\"database/DB_youth.csv\", index=False)\n",
        "    #Update Repository\n",
        "    #update last referance date for returning members,\n",
        "    #update new members to DB\n",
        "    DB = pd.read_csv(master_path + \"database/DB_youth.csv\", index_col=\"UID\")\n",
        "    #update archive first\n",
        "    format = '%Y-%m-%d %H:%M:%S'\n",
        "    DB.to_csv(master_path + f\"database/archive/DB_youth/DB_youth_{pd.Timestamp.today().strftime(format)}.csv\",\n",
        "              index=True)\n",
        "\n",
        "    new_df = df.copy()\n",
        "    temp_new_df = new_df.copy()\n",
        "    # for row_number, row in temp_new_df.iterrows():\n",
        "\n",
        "    #     row_email = row[\"Email\"]\n",
        "    #     row_phone = row[\"Whatsapp/mobile Number\"]\n",
        "\n",
        "    #     #drop row if email/phone already exists\n",
        "    #     #update last referance date in DB to today()\n",
        "    #     if row_email in DB[\"Email\"].values:\n",
        "    #         new_df = new_df[new_df[\"Email\"] != row_email]\n",
        "    #         DB.loc[DB[\"Email\"] == row_email, \"last_referance\"] = pd.Timestamp.today()\n",
        "    #     elif row_phone in DB[\"Whatsapp/mobile Number\"].values:\n",
        "    #         new_df = new_df[new_df[\"Whatsapp/mobile Number\"] != row_phone]\n",
        "    #         DB.loc[DB[\"Whatsapp/mobile Number\"] == row_phone, \"last_referance\"] = pd.Timestamp.today()\n",
        "\n",
        "    # Extract unique emails and phone numbers from DB for faster access\n",
        "    existing_emails = set(DB[\"Email\"])\n",
        "    existing_phones = set(DB[\"Whatsapp/mobile Number\"])\n",
        "\n",
        "    # Lists to collect duplicate emails and phones\n",
        "    duplicate_emails = []\n",
        "    duplicate_phones = []\n",
        "\n",
        "    # Iterate through temp_new_df to identify duplicates\n",
        "    for _, row in temp_new_df.iterrows():\n",
        "        row_email = row[\"Email\"]\n",
        "        row_phone = row[\"Whatsapp/mobile Number\"]\n",
        "\n",
        "        if row_email in existing_emails:\n",
        "            duplicate_emails.append(row_email)\n",
        "        if row_phone in existing_phones:\n",
        "            duplicate_phones.append(row_phone)\n",
        "\n",
        "    # Remove rows with duplicate emails or phones from new_df\n",
        "    new_df = new_df[~new_df[\"Email\"].isin(duplicate_emails)]\n",
        "    new_df = new_df[~new_df[\"Whatsapp/mobile Number\"].isin(duplicate_phones)]\n",
        "\n",
        "    # Update last_referance in DB for the duplicates\n",
        "    DB.loc[DB[\"Email\"].isin(duplicate_emails), \"last_referance\"] = pd.Timestamp.today()\n",
        "    DB.loc[DB[\"Whatsapp/mobile Number\"].isin(duplicate_phones), \"last_referance\"] = pd.Timestamp.today()\n",
        "\n",
        "\n",
        "    #update DB index name\n",
        "    #update new_df index name, set index to UID, update last_referance date\n",
        "    new_df.reset_index(drop=True,\n",
        "                    inplace=True)\n",
        "\n",
        "    if np.isnan(DB.index.max()) or DB.index.max() < 100:\n",
        "        next_UID = 100\n",
        "    else:\n",
        "        next_UID = DB.index.max() + 1\n",
        "\n",
        "    new_df[\"UID\"] = new_df.index + next_UID\n",
        "    new_df.set_index(\"UID\",\n",
        "                    drop=True,\n",
        "                    inplace=True)\n",
        "    new_df[\"last_referance\"] = pd.Timestamp.today()\n",
        "\n",
        "    #add new_df to DB and sort by UID index\n",
        "    DB = pd.concat([DB, new_df],\n",
        "                axis=0)\n",
        "    DB.sort_index(inplace=True)\n",
        "\n",
        "    #drop index of members not achive for > 6 months,\n",
        "    #redesignate UID to new members first,\n",
        "    #if there are underflow, add to excess UID .csv tracker file for next update\n",
        "    DB[\"last_referance\"] = pd.to_datetime(DB[\"last_referance\"])\n",
        "    seven_mths_ago = pd.Timestamp.today() - pd.DateOffset(months=7)\n",
        "    DB = DB[DB[\"last_referance\"] > seven_mths_ago]\n",
        "\n",
        "    #update DB csv\n",
        "    DB.to_csv(master_path + \"database/DB_youth.csv\", index=True)\n",
        "\n",
        "    '''\n",
        "    Generate name tags to be printed for new members\n",
        "    PDF will be saved in directory name_tags_ToBePrinted/\n",
        "    '''\n",
        "    generate_name_tags(new_df[\"full_name\"],\n",
        "                       group=\"youth\")\n",
        "\n",
        "    '''\n",
        "    Generate contacts to be saved\n",
        "    '''\n",
        "    contact_log = pd.read_csv(master_path + \"database/contact_log.csv\").values.ravel()\n",
        "    new_df = new_df[~new_df[\"Whatsapp/mobile Number\"].isin(contact_log)]\n",
        "    new_df['School/Company'] = new_df['School/Company'].apply(lambda x: \"NUS\" if normalize_string(x) in [\"nationaluniversityofsingapore\", \"nus\"] else x)\n",
        "    new_df['School/Company'] = new_df['School/Company'].apply(lambda x: \"NUS\" if \"nus\" in normalize_string(x) else x)\n",
        "    smu_variations = [\n",
        "    \"singaporemanagementuniversity\",\n",
        "    \"smu\",\n",
        "    \"smuschoolofaccountancy\",\n",
        "    \"smuschoolofcomputingandinformationsystems\",\n",
        "    \"smuschoolofsocialsciences\",\n",
        "    \"smuleekongchianschoolofbusiness\"\n",
        "    ]\n",
        "    new_df['School/Company'] = new_df['School/Company'].apply(lambda x: \"SMU\" if normalize_string(x) in smu_variations else x)\n",
        "    new_df['School/Company'] = new_df['School/Company'].apply(lambda x: \"SMU\" if \"smu\" in normalize_string(x) else x)\n",
        "\n",
        "\n",
        "    ### NUS ###\n",
        "    # Create vCard file named 'contacts.vcf'\n",
        "    time_format = '%Y-%m-%d %H:%M:%S'\n",
        "    #archive update\n",
        "    create_vcard(new_df[new_df[\"School/Company\"] == \"NUS\"], master_path + f'contact/archive/contacts_{pd.Timestamp.today().strftime(time_format)}_NUS.vcf')\n",
        "    #save as most recent\n",
        "    create_vcard(new_df[new_df[\"School/Company\"] == \"NUS\"], master_path + f'contact/contacts_youth_NUS.vcf')\n",
        "\n",
        "    ### SMU ###\n",
        "    # Create vCard file named 'contacts.vcf'\n",
        "    time_format = '%Y-%m-%d %H:%M:%S'\n",
        "    #archive update\n",
        "    create_vcard(new_df[new_df[\"School/Company\"] == \"SMU\"], master_path + f'contact/archive/contacts_{pd.Timestamp.today().strftime(time_format)}_SMU.vcf')\n",
        "    #save as most recent\n",
        "    create_vcard(new_df[new_df[\"School/Company\"] == \"SMU\"], master_path + f'contact/contacts_youth_SMU.vcf')\n",
        "\n",
        "    ### Others ###\n",
        "    # Create vCard file named 'contacts.vcf'\n",
        "    time_format = '%Y-%m-%d %H:%M:%S'\n",
        "    #archive update\n",
        "    create_vcard(new_df[~((new_df[\"School/Company\"] == \"NUS\") | (new_df[\"School/Company\"] == \"SMU\"))], master_path + f'contact/archive/contacts_{pd.Timestamp.today().strftime(time_format)}_OTHERS.vcf')\n",
        "    #save as most recent\n",
        "    create_vcard(new_df[~((new_df[\"School/Company\"] == \"NUS\") | (new_df[\"School/Company\"] == \"SMU\"))], master_path + f'contact/contacts_youth_OTHERS.vcf')\n",
        "\n",
        "    #update contact log\n",
        "    contact_log_df = pd.DataFrame(contact_log, columns=[\"Whatsapp/mobile Number\"])\n",
        "    combined_df = pd.concat([contact_log_df, new_df[[\"Whatsapp/mobile Number\"]]], ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "    # '''\n",
        "    # autogenerate welcome email for new members\n",
        "    # '''\n",
        "    # sender= \"Wilfred\"\n",
        "    # hike_date = \"29th July\"\n",
        "    # location = \"Punggol MRT, Exit A\"\n",
        "    # time = \"9.20am\"\n",
        "    # message_lst = []\n",
        "\n",
        "    # for name in df_message[\"full_name\"]:\n",
        "    #     message = f\"\"\"\n",
        "    #                 Hi *{name}*, this is *{sender}*, the student coordinator for *SMC*.\n",
        "    #                 For the *{hike_date}* SMC Youths Hiking Library event, do be reminded to be at\n",
        "    #                 *{location + \" \" + \"by\" + \" \" + time}*. We will carry on with the event regardless of rain or shine.\n",
        "    #                 The finalised participants' list and pairing table will also be sent to you on Sat morning.\n",
        "\n",
        "    #                 Do kindly \"follow\" *SMC LinkedIn* at  https://www.linkedin.com/company/smcmentorship/\n",
        "    #                 for future events' announcements and publication of youths' reflection articles and feedback.\n",
        "    #                 Please feel free to reach out if you have any queries as well. Thank you!\n",
        "\n",
        "    #                 *Kindly acknowledge and confirm.*\n",
        "    #                 \"\"\"\n",
        "    # #insert function for this(TODO)\n",
        "\n",
        "    print(\"Youth Processed\")\n",
        "    return None\n",
        "\n",
        "\n",
        "def process_mentor():\n",
        "\n",
        "    df = pd.read_excel(master_path + \"raw_data/Members_Mentor_Default View.xlsx\")\n",
        "\n",
        "    earliest_date = get_earliest_date(df)\n",
        "\n",
        "    #filter for rows with earliest date\n",
        "    df = df[df[\"Date of Hike\"].str.contains(earliest_date)]\n",
        "    df[\"full_name\"] = df[\"First_Name\"] + \" \" + df[\"Last_Name\"]\n",
        "    df[\"Date of Hike\"] = earliest_date\n",
        "\n",
        "    df = df[['Date of Hike', 'full_name', 'Company',\n",
        "    'Title','Industry', 'Email', 'Whatsapp/mobile Number']]\n",
        "\n",
        "    df.drop_duplicates(subset=[\"Email\", \"Whatsapp/mobile Number\"],\n",
        "                    keep=\"first\",\n",
        "                    inplace=True)\n",
        "    df.reset_index(drop=True,\n",
        "                inplace=True)\n",
        "\n",
        "    # df.to_csv(\"database/DB_mentor.csv\", index=False)\n",
        "    #Update Repository\n",
        "    #update last referance date for returning members,\n",
        "    #update new members to DB\n",
        "    DB = pd.read_csv(master_path + \"database/DB_mentor.csv\", index_col=\"UID\")\n",
        "    #update archive first\n",
        "    format = '%Y-%m-%d %H:%M:%S'\n",
        "    DB.to_csv(master_path + f\"database/archive/DB_mentor/DB_mentor_{pd.Timestamp.today().strftime(format)}.csv\",\n",
        "              index=True)\n",
        "\n",
        "    new_df = df.copy()\n",
        "    temp_new_df = new_df.copy()\n",
        "    for row_number, row in temp_new_df.iterrows():\n",
        "\n",
        "        row_email = row[\"Email\"]\n",
        "        row_phone = row[\"Whatsapp/mobile Number\"]\n",
        "\n",
        "        #drop row if email/phone already exists\n",
        "        #update last referance date in DB to today()\n",
        "        if row_email in DB[\"Email\"].values:\n",
        "            new_df = new_df[new_df[\"Email\"] != row_email]\n",
        "            DB.loc[DB[\"Email\"] == row_email, \"last_referance\"] = pd.Timestamp.today()\n",
        "        elif row_phone in DB[\"Whatsapp/mobile Number\"].values:\n",
        "            new_df = new_df[new_df[\"Whatsapp/mobile Number\"] != row_phone]\n",
        "            DB.loc[DB[\"Whatsapp/mobile Number\"] == row_phone, \"last_referance\"] = pd.Timestamp.today()\n",
        "\n",
        "    #update DB index name\n",
        "    #update new_df index name, set index to UID, update last_referance date\n",
        "    new_df.reset_index(drop=True,\n",
        "                    inplace=True)\n",
        "\n",
        "    if np.isnan(DB.index.max()) or DB.index.max() < 100:\n",
        "        next_UID = 100\n",
        "    else:\n",
        "        next_UID = DB.index.max() + 1\n",
        "\n",
        "    new_df[\"UID\"] = new_df.index + next_UID\n",
        "    new_df.set_index(\"UID\",\n",
        "                    drop=True,\n",
        "                    inplace=True)\n",
        "    new_df[\"last_referance\"] = pd.Timestamp.today()\n",
        "\n",
        "    #add new_df to DB and sort by UID index\n",
        "    DB = pd.concat([DB, new_df],\n",
        "                axis=0)\n",
        "    DB.sort_index(inplace=True)\n",
        "\n",
        "    #drop index of members not achive for > 6 months,\n",
        "    #redesignate UID to new members first,\n",
        "    #if there are underflow, add to excess UID .csv tracker file for next update\n",
        "    DB[\"last_referance\"] = pd.to_datetime(DB[\"last_referance\"])\n",
        "    seven_mths_ago = pd.Timestamp.today() - pd.DateOffset(months=7)\n",
        "    DB = DB[DB[\"last_referance\"] > seven_mths_ago]\n",
        "\n",
        "    #update DB csv\n",
        "    DB.to_csv(master_path + \"database/DB_mentor.csv\", index=True)\n",
        "\n",
        "    '''\n",
        "    Generate name tags to be printed for new members\n",
        "    PDF will be saved in directory name_tags_ToBePrinted/\n",
        "    '''\n",
        "    generate_name_tags(new_df[\"full_name\"],\n",
        "                       group=\"mentor\")\n",
        "\n",
        "    print(\"Mentor Processed\")\n",
        "    return None\n",
        "\n",
        "def Reserved_unique_ID_print(group):\n",
        "\n",
        "    if group.lower() == \"mentor\":\n",
        "        df = pd.read_csv(master_path + \"database/Reserved_UID_mentor.csv\", index_col=\"UID\")\n",
        "\n",
        "    elif group.lower() == \"youth\":\n",
        "        df = pd.read_csv(master_path + \"database/Reserved_UID_youth.csv\", index_col=\"UID\")\n",
        "\n",
        "\n",
        "    '''\n",
        "    Generate name tags to be printed for new members\n",
        "    PDF will be saved in directory name_tags_ToBePrinted/\n",
        "    '''\n",
        "    generate_name_tags(df[\"full_name\"],\n",
        "                       group=group,\n",
        "                       reserved=True)\n",
        "\n",
        "    print(\"Reserved UID Processed\")\n",
        "    return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlfdPJ_9CgKb",
        "outputId": "4638323d-49ee-44c5-aad4-8fd9d2c975e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Youth Processed\n",
            "Mentor Processed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-66-90a8cc554a97>:375: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  elif row_phone in DB[\"Whatsapp/mobile Number\"].values:\n"
          ]
        }
      ],
      "source": [
        "process_youth()\n",
        "process_mentor()\n",
        "# Reserved_unique_ID_print(group=\"mentor\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contact_log = pd.read_csv(master_path + \"database/contact_log.csv\").values.ravel()\n",
        "contact_log.shape"
      ],
      "metadata": {
        "id": "qS4zvgmYUOZI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc3048c-c8df-4d7f-c79f-eff751d4971f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(198,)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "smc_contact_table-F01-ayo0",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}